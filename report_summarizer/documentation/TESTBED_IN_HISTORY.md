# Testbed Information in History Display

## ğŸ¯ Goal

Add testbed information (region and environment) to the history sidebar so users can quickly:
- Identify which region tests ran in (eu_central_1, us_east_1, etc.)
- Identify which environment was used (staging, qatest, production)
- Compare results from same/different regions
- Filter by environment for targeted analysis

## âœ… Implementation

### Testbed Format

Testbeds follow this naming pattern:
```
{region}_{environment}_{service}_api_{timestamp}
```

**Examples:**
- `eu_central_1_staging_sars_api_20260120_104005`
- `us_east_1_qatest_sars_api_20260121_090045`
- `us_west_2_production_imm_api_20260119_153020`
- `ap_south_1_staging_imm_api_20260118_120030`

### Parsing Logic

**File**: `utils/session_manager.py`

```python
# Extract testbed information
testbed = summary_data.get('Test_bed', '')

# Parse to extract region and environment
# Format: eu_central_1_staging_sars_api_20260120_104005
region = ''
environment = ''

if testbed:
    parts = testbed.split('_')
    # First 3 parts are the region (e.g., eu_central_1)
    if len(parts) >= 3:
        region = '_'.join(parts[:3])
    # 4th part is the environment (staging, qatest, production)
    if len(parts) >= 4:
        environment = parts[3]
```

### Display Format

**Before (no testbed info):**
```
staging_sars_sanity_build_7500
ğŸ“… 2026-01-21 22:30:00 | ğŸ” FULL
âœ… 151/155 passed (97.4%)
```

**After (with testbed info):**
```
staging_sars_sanity_build_7500
ğŸŒ eu_central_1 | ğŸ·ï¸ staging
ğŸ“… 2026-01-21 22:30:00 | ğŸ” FULL
âœ… 151/155 passed (97.4%)
```

## ğŸ“Š Examples

### History Sidebar Display

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ History (3/8)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â˜ staging_sars_sanity_build_7500        â”‚
â”‚   ğŸŒ eu_central_1 | ğŸ·ï¸ staging          â”‚
â”‚   ğŸ“… 2026-01-21 22:30:00 | ğŸ” FULL      â”‚
â”‚   âœ… 151/155 passed (97.4%)             â”‚
â”‚   [ğŸ‘ï¸ View]                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â˜ qatest_sars_sanity_build_7499         â”‚
â”‚   ğŸŒ us_east_1 | ğŸ·ï¸ qatest              â”‚
â”‚   ğŸ“… 2026-01-21 21:45:00 | ğŸ” QUICK     â”‚
â”‚   âœ… 161/171 passed (94.2%)             â”‚
â”‚   [ğŸ‘ï¸ View]                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â˜ production_imm_sanity_build_8875      â”‚
â”‚   ğŸŒ us_west_2 | ğŸ·ï¸ production          â”‚
â”‚   ğŸ“… 2026-01-21 20:15:00 | ğŸ” FULL      â”‚
â”‚   âœ… 168/170 passed (98.8%)             â”‚
â”‚   [ğŸ‘ï¸ View]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Use Cases

### Use Case 1: Regional Comparison

**Scenario**: Compare test results across different regions

```
History shows:
  â˜ build_7500 | ğŸŒ eu_central_1 | ğŸ·ï¸ staging | âœ… 97.4%
  â˜ build_7501 | ğŸŒ us_east_1    | ğŸ·ï¸ staging | âœ… 95.2%
  â˜ build_7502 | ğŸŒ us_west_2    | ğŸ·ï¸ staging | âœ… 98.1%

Observation:
  - EU Central: 97.4% pass rate
  - US East: 95.2% pass rate âš ï¸ Lower!
  - US West: 98.1% pass rate

Action: Investigate US East region-specific issues
```

### Use Case 2: Environment Validation

**Scenario**: Verify staging matches production

```
History shows:
  â˜ build_7500 | ğŸŒ eu_central_1 | ğŸ·ï¸ staging    | âœ… 97.4%
  â˜ build_7500 | ğŸŒ eu_central_1 | ğŸ·ï¸ production | âœ… 97.8%

Observation:
  - Same region, same build
  - Similar pass rates (97.4% vs 97.8%)
  - Staging validated for production

Action: Safe to promote to production
```

### Use Case 3: QAtest vs. Staging

**Scenario**: Compare QAtest and staging environments

```
History shows:
  â˜ build_7499 | ğŸŒ us_east_1 | ğŸ·ï¸ qatest  | âœ… 94.2%
  â˜ build_7499 | ğŸŒ us_east_1 | ğŸ·ï¸ staging | âœ… 97.4%

Observation:
  - Same region, same build
  - QAtest has lower pass rate (94.2% vs 97.4%)
  - Environment parity issue

Action: Investigate QAtest environment configuration
```

### Use Case 4: Multi-Region Rollout

**Scenario**: Rolling out to multiple regions, track progress

```
History shows:
  â˜ build_8000 | ğŸŒ us_west_2    | ğŸ·ï¸ production | âœ… 99.1% âœ…
  â˜ build_8000 | ğŸŒ us_east_1    | ğŸ·ï¸ production | âœ… 98.5% âœ…
  â˜ build_8000 | ğŸŒ eu_central_1 | ğŸ·ï¸ production | âœ… 98.9% âœ…
  â˜ build_8000 | ğŸŒ ap_south_1   | ğŸ·ï¸ production | âŒ 87.2% âš ï¸

Observation:
  - US/EU regions: All >98% pass rate
  - AP South: Only 87.2% pass rate

Action: Hold AP South rollout, investigate regional issues
```

### Use Case 5: Flaky Region Detection

**Scenario**: Identify if a region has infrastructure problems

```
History over time:
  build_7495 | ğŸŒ eu_central_1 | ğŸ·ï¸ staging | âœ… 95.2%
  build_7496 | ğŸŒ eu_central_1 | ğŸ·ï¸ staging | âœ… 96.1%
  build_7497 | ğŸŒ eu_central_1 | ğŸ·ï¸ staging | âœ… 89.5% âš ï¸
  build_7498 | ğŸŒ eu_central_1 | ğŸ·ï¸ staging | âœ… 90.2% âš ï¸
  build_7499 | ğŸŒ eu_central_1 | ğŸ·ï¸ staging | âœ… 94.8%

Observation:
  - EU Central staging had dip in builds 7497-7498
  - Recovered in 7499
  - Possible infrastructure hiccup

Action: Review EU Central infrastructure logs for that time period
```

## ğŸ” Parsing Details

### Region Extraction

Regions are the first 3 underscore-separated parts:

| Testbed | Region |
|---------|--------|
| `eu_central_1_staging_sars_api_...` | `eu_central_1` |
| `us_east_1_qatest_sars_api_...` | `us_east_1` |
| `us_west_2_production_imm_api_...` | `us_west_2` |
| `ap_south_1_staging_imm_api_...` | `ap_south_1` |
| `ap_southeast_1_qatest_sars_api_...` | `ap_southeast_1` |

### Environment Extraction

Environment is the 4th underscore-separated part:

| Testbed | Environment |
|---------|-------------|
| `eu_central_1_staging_sars_api_...` | `staging` |
| `us_east_1_qatest_sars_api_...` | `qatest` |
| `us_west_2_production_imm_api_...` | `production` |

### Fallback Handling

```python
# If testbed doesn't follow expected format
if not testbed:
    # Don't show region/environment line
    pass

# If parsing fails
if not region and not environment:
    # Don't show region/environment line
    pass
```

## ğŸ“‹ Benefits

### Quick Identification
- âœ… Instantly see which region test ran in
- âœ… Instantly see which environment
- âœ… No need to expand details or check metadata

### Easy Comparison
- âœ… Compare same region across builds
- âœ… Compare different regions for same build
- âœ… Compare environments (staging vs production)

### Better Decision Making
- âœ… Regional rollout decisions
- âœ… Environment parity validation
- âœ… Infrastructure issue detection
- âœ… Targeted debugging

### Improved Workflow
- âœ… Filter mentally by region/environment
- âœ… Quickly find relevant comparisons
- âœ… Spot patterns in failures
- âœ… Track regional health over time

## ğŸ¨ Design Choices

### 1. **Separate Line for Testbed Info**
```
staging_sars_sanity_build_7500
ğŸŒ eu_central_1 | ğŸ·ï¸ staging      â† Separate line
ğŸ“… 2026-01-21 22:30:00 | ğŸ” FULL
```
**Why**: Keeps build name clean, groups related info (region/env)

### 2. **Emoji Icons**
- ğŸŒ for Region - Universal globe symbol
- ğŸ·ï¸ for Environment - Tag/label symbol
**Why**: Quick visual identification, consistent with rest of UI

### 3. **Pipe Separator**
```
ğŸŒ eu_central_1 | ğŸ·ï¸ staging
```
**Why**: Clear separation, easy to scan

### 4. **Abbreviated Display**
- Region: `eu_central_1` (not full testbed)
- Environment: `staging` (not full testbed)
**Why**: Compact, shows only relevant info

### 5. **Conditional Display**
- Only show line if testbed data exists
**Why**: Graceful degradation for old data or missing testbed

## ğŸ“Š Visual Impact

### Sidebar Space Usage

**Before**: 3 lines per entry
```
staging_sars_sanity_build_7500
ğŸ“… 2026-01-21 22:30:00 | ğŸ” FULL
âœ… 151/155 passed (97.4%)
```

**After**: 4 lines per entry
```
staging_sars_sanity_build_7500
ğŸŒ eu_central_1 | ğŸ·ï¸ staging
ğŸ“… 2026-01-21 22:30:00 | ğŸ” FULL
âœ… 151/155 passed (97.4%)
```

**Trade-off**: +1 line per entry, but provides critical context

**With 8 entries**: +8 lines total (acceptable with compact UI)

## ğŸ”§ Technical Details

### Data Flow

```
1. User analyzes report
   â†“
2. Analyzer extracts testbed from index.html
   â†“
3. Stored in analyzer_results['summary']['Test_bed']
   â†“
4. SessionManager.add_to_history() saves entry
   â†“
5. SessionManager.format_history_summary() parses testbed
   â†“
6. Displays region and environment in sidebar
```

### Code Location

**File**: `utils/session_manager.py`
**Function**: `format_history_summary()`
**Lines**: ~165-175 (testbed parsing and display)

### Compatibility

- âœ… Works with existing history entries (gracefully handles missing testbed)
- âœ… Works with all testbed formats (flexible parsing)
- âœ… No changes needed to other components
- âœ… Backward compatible

## ğŸ‰ Summary

**Added**: Region and environment display in history sidebar

**Format**:
```
ğŸŒ {region} | ğŸ·ï¸ {environment}
```

**Benefits**:
- âœ… Quick identification of test environment
- âœ… Easy regional comparison
- âœ… Better decision making
- âœ… Improved debugging workflow

**Impact**: Makes it immediately clear where tests ran, enabling better comparisons and faster triage!

---

**Now you can instantly see if tests ran in EU vs US, staging vs production - critical for regional rollouts and environment validation!** ğŸš€

